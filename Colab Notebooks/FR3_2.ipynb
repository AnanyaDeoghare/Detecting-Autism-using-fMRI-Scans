{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FR3_2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Eh5RRpybIyBH","colab_type":"code","colab":{}},"source":["#! git clone https://Nusha:inceptionv3@gitlab.com/Nusha/abcdefghi"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HLPzkdTNI0QK","colab_type":"code","colab":{}},"source":["import torch\n","import numpy as np\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data.sampler import SubsetRandomSampler"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8JA-PRBI29j","colab_type":"code","colab":{}},"source":["# how many samples per batch to load\n","batch_size = 64\n","# percentage of training set to use as validation\n","test_size = 0.3\n","valid_size = 0.1\n","\n","# convert data to a normalized torch.FloatTensor\n","transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(20),\n","    transforms.Resize(size=(224,224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])\n","\n","data = datasets.ImageFolder('abcdefghi/data_die',transform=transform)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ouILpDn8I5kd","colab_type":"code","colab":{}},"source":["#For test\n","num_data = len(data)\n","indices_data = list(range(num_data))\n","np.random.shuffle(indices_data)\n","split_tt = int(np.floor(test_size * num_data))\n","train_idx, test_idx = indices_data[split_tt:], indices_data[:split_tt]\n","\n","#For Valid\n","num_train = len(train_idx)\n","indices_train = list(range(num_train))\n","np.random.shuffle(indices_train)\n","split_tv = int(np.floor(valid_size * num_train))\n","train_new_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv]\n","\n","\n","# define samplers for obtaining training and validation batches\n","train_sampler = SubsetRandomSampler(train_new_idx)\n","test_sampler = SubsetRandomSampler(test_idx)\n","valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size,\n","    sampler=train_sampler, num_workers=1)\n","valid_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, \n","    sampler=valid_sampler, num_workers=1)\n","test_loader = torch.utils.data.DataLoader(data, sampler = test_sampler, batch_size=batch_size, \n","    num_workers=1)\n","classes = [0,1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBeGOwP4I8-X","colab_type":"code","colab":{}},"source":["len(test_loader)*batch_size + len(valid_loader)*batch_size + len(train_loader)*batch_size\n","for batch in valid_loader:\n","    print(batch[0].size())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TeumCinAJA2V","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# helper function to un-normalize and display an image\n","def imshow(img):\n","    img = img / 2 + 0.5  # unnormalize\n","    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n","    \n","# obtain one batch of training images\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","images = images.numpy() # convert images to numpy for display\n","\n","# plot the images in the batch, along with the corresponding labels\n","fig = plt.figure(figsize=(10, 4))\n","# display 20 images\n","for idx in np.arange(10):\n","    ax = fig.add_subplot(2, 10/2, idx+1, xticks=[], yticks=[])\n","    imshow(images[idx])\n","    ax.set_title(classes[labels[idx]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D4-zECmdJG48","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","train_on_gpu = torch.cuda.is_available()\n","# define the CNN architecture\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # convolutional layer\n","        self.conv1 = nn.Conv2d(3, 16, 3)   \n","        #self.conv2 = nn.Conv2d(16, 16, 3)\n","        self.conv3 = nn.Conv2d(16, 32, 3)   \n","        \n","        # max pooling layer\n","        self.pool = nn.MaxPool2d(2, 2)     \n","        \n","        self.dropout = nn.Dropout(0.2)\n","        \n","        self.fc1 = nn.Linear(32*54*54 , 256)  \n","        self.fc2 = nn.Linear(256, 84)\n","        self.fc3 = nn.Linear(84, 2)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","        \n","\n","\n","        \n","    def forward(self, x):\n","        # add sequence of convolutional and max pooling layers\n","        x = self.pool(F.relu(self.conv1(x)))# 224 -> 222 -> 111\n","        #x = self.pool(F.relu(self.conv2(x))) # 111 -> 109 -> 54\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = self.dropout(x)\n","        x = x.view(-1, 32*54*54)   #32*53*53\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(F.relu(self.fc2(x)))\n","        x = self.softmax(self.fc3(x))\n","        x = self.softmax(x)\n","\n","        return x\n","\n","# create a complete CNN\n","model = Net()\n","print(model)\n","\n","# move tensors to GPU if CUDA is available\n","if train_on_gpu:\n","    model.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XYnSD_4uJzKB","colab_type":"code","colab":{}},"source":["# Loss function\n","criterion = torch.nn.CrossEntropyLoss()\n","# Optimizer\n","optimizer = torch.optim.SGD(model.parameters(), lr = 0.003, momentum= 0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6zLpsK0qJ3MK","colab_type":"code","colab":{}},"source":["# number of epochs to train the model\n","n_epochs = 700 # you may increase this number to train a final model\n","\n","valid_loss_min = np.Inf # track change in validation loss\n","\n","for epoch in range(1, n_epochs+1):\n","\n","    # keep track of training and validation loss\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","    \n","    ###################\n","    # train the model #\n","    ###################\n","    model.train()\n","    for data, target in train_loader:\n","        # move tensors to GPU if CUDA is available\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","        # clear the gradients of all optimized variables\n","        optimizer.zero_grad()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        # calculate the batch loss\n","        loss = criterion(output, target)\n","        # backward pass: compute gradient of the loss with respect to model parameters\n","        loss.backward()\n","        # perform a single optimization step (parameter update)\n","        optimizer.step()\n","        # update training loss\n","        train_loss += loss.item()*data.size(0)\n","        \n","    ######################    \n","    # validate the model #\n","    ######################\n","    model.eval()\n","    for data, target in valid_loader:\n","        # move tensors to GPU if CUDA is available\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        # calculate the batch loss\n","        loss = criterion(output, target)\n","        # update average validation loss \n","        valid_loss += loss.item()*data.size(0)\n","    \n","    # calculate average losses\n","    train_loss = train_loss/len(train_loader.dataset)\n","    valid_loss = valid_loss/len(valid_loader.dataset)\n","        \n","    # print training/validation statistics \n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","        epoch, train_loss, valid_loss))\n","    \n","    # save model if validation loss has decreased\n","    if valid_loss <= valid_loss_min:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","        valid_loss_min,\n","        valid_loss))\n","        torch.save(model.state_dict(), 'model_cifar.pt')\n","        valid_loss_min = valid_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K-M9nKyYJ-JJ","colab_type":"code","colab":{}},"source":["# track test loss\n","test_loss = 0.0\n","class_correct = list(0. for i in range(2))\n","class_total = list(0. for i in range(2))\n","\n","print('\\n FR 3 kernel _2')\n","print(n_epochs)\n","\n","model.eval()\n","i=1\n","# iterate over test data\n","len(test_loader)\n","for data, target in test_loader:\n","    i=i+1\n","    if len(target)!=batch_size:\n","        continue\n","        \n","    # move tensors to GPU if CUDA is available\n","    if train_on_gpu:\n","        data, target = data.cuda(), target.cuda()\n","    # forward pass: compute predicted outputs by passing inputs to the model\n","    output = model(data)\n","    # calculate the batch loss\n","    loss = criterion(output, target)\n","    # update test loss \n","    test_loss += loss.item()*data.size(0)\n","    # convert output probabilities to predicted class\n","    _, pred = torch.max(output, 1)    \n","    # compare predictions to true label\n","    correct_tensor = pred.eq(target.data.view_as(pred))\n","    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n","    # calculate test accuracy for each object class\n","#     print(target)\n","    \n","    for i in range(batch_size):       \n","        label = target.data[i]\n","        class_correct[label] += correct[i].item()\n","        class_total[label] += 1\n","\n","# average test loss\n","test_loss = test_loss/len(test_loader.dataset)\n","print('Test Loss: {:.6f}\\n'.format(test_loss))\n","\n","for i in range(2):\n","    if class_total[i] > 0:\n","        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n","            classes[i], 100 * class_correct[i] / class_total[i],\n","            np.sum(class_correct[i]), np.sum(class_total[i])))\n","    else:\n","        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n","\n","print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n","    100. * np.sum(class_correct) / np.sum(class_total),\n","    np.sum(class_correct), np.sum(class_total)))"],"execution_count":0,"outputs":[]}]}