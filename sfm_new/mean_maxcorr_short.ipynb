{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/__init__.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/extmath.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/extmath.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sparsefuncs_fast import csr_row_norms\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/cluster/supervised.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .expected_mutual_info_fast import expected_mutual_information\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/pairwise.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .pairwise_fast import _chi2_kernel_fast, _sparse_manhattan\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/random.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._random import sample_without_replacement\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import libsvm, liblinear\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import libsvm_sparse\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.py:35: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ..utils.seq_dataset import ArrayDataset, CSRDataset\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/least_angle.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ..utils import arrayfuncs, as_float_array, check_X_y, deprecated\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:29: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import cd_fast\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/__init__.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/sag.py:12: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sag_fast import sag\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ball_tree import BallTree\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .kd_tree import KDTree\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from scipy import linalg,signal\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "asd_data = sio.loadmat('whole_asd_fmri.mat')\n",
    "nt_data = sio.loadmat('whole_tdc_fmri.mat')\n",
    "\n",
    "def normalise_matrix (matrix1, matrix2, matrix3 ):\n",
    "\tfor l in range (0,90):\n",
    "\t\ta11 = np.trim_zeros(matrix2[l])\n",
    "\t\ta11_len = len(a11)\n",
    "\t\tfor m in range (0,a11_len): \n",
    "\t\t\ta11[m] = a11[m] - matrix3[l]\n",
    "\t\tu = 500 - a11_len\n",
    "\t\ta11 = np.pad(a11,(0,u),'constant',constant_values=0)\n",
    "\t\ta11 = np.asarray(a11)\n",
    "\t\tmatrix1[l] = a11\n",
    "\n",
    "\t\n",
    "def mean_row(matrix1):\n",
    "\tr = np.zeros([90,1])\n",
    "\tfor i in range(0,90):\n",
    "\t\tr[i] = np.mean(np.trim_zeros(matrix1[i]))\n",
    "\tr=np.reshape(r,(90,1))\n",
    "\treturn r\n",
    "\n",
    "na = 443\n",
    "nn = 435\n",
    "x = asd_data['x']\n",
    "x = np.transpose(x,(2,1,0))\n",
    "\n",
    "y = nt_data['y']\n",
    "y = np.transpose(y,(2,1,0))\n",
    "\n",
    "\n",
    "# autistic and neurotypical arrays\n",
    "a = np.ndarray(shape = (438,) , dtype=\"object\")\n",
    "n = np.ndarray(shape = (434,) , dtype=\"object\")\n",
    "\n",
    "#mean of each row of the matrices use axis=1\n",
    "ma = np.ndarray(shape = (438,90,1) , dtype=\"object\")\n",
    "mn = np.ndarray(shape = (434,90,1) , dtype=\"object\")\n",
    "\n",
    "#normalised input matrices\n",
    "xa = np.ndarray(shape = (438,) , dtype=\"object\")\n",
    "xn = np.ndarray(shape = (434,) , dtype=\"object\")\n",
    "\n",
    "cnt1=0\n",
    "for i in range(0,na): \n",
    "\tif((i != 6) and (i != 7) and (i != 10) and (i!= 325) and (i!= 330) ):\n",
    "\t\ta[cnt1] = x[i]\n",
    "\t\tcnt1 = cnt1+1\n",
    "\t\t\n",
    "\n",
    "cnt2=0\n",
    "for j in range(0,nn):\n",
    "\tif(( j != 62)):\n",
    "\t\tn[cnt2] = y[j]\n",
    "\t\tcnt2 = cnt2+1\n",
    "\n",
    "na=438\n",
    "nn=434\n",
    "for i in range(0, na):\n",
    "\txa[i] = np.zeros((90,500))\n",
    "\n",
    "for j in range(0, nn):\n",
    "\txn[j] = np.zeros((90,500))\n",
    "\n",
    "#finding mean of every row in 2d matrix for each subject\n",
    "\n",
    "for i in range(0,na):\n",
    "\tma[i] = mean_row(a[i])\n",
    "\n",
    "for j in range(0,nn):\n",
    "\tmn[j] = mean_row(n[j])\n",
    "\n",
    "#getting normalised matrix\n",
    "\n",
    "for i in range(0,na):\n",
    "\tnormalise_matrix(xa[i],a[i],ma[i])\n",
    "\t\n",
    "for j in range(0,nn):\n",
    "\tnormalise_matrix(xn[j],n[j],mn[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/scipy/signal/signaltools.py:492: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return x[reverse].conj()\n"
     ]
    }
   ],
   "source": [
    "no_train = 786\n",
    "no_test = (na+nn) - no_train\n",
    "xta = int(no_train/2) + 2       #329\n",
    "xtn = no_train - xta            #326\n",
    "\n",
    "np.random.shuffle(xa)   #shuffles the matrix and saves in itself, returns nothing\n",
    "np.random.shuffle(xn)\n",
    "\n",
    "xa_train = np.ndarray(shape = (xta,90,500) , dtype=\"object\")\n",
    "xa_test = np.ndarray(shape = ((na-xta),90,500) , dtype=\"object\")\n",
    "xn_train = np.ndarray(shape = (xtn,90,500) , dtype=\"object\")\n",
    "xn_test = np.ndarray(shape = ((nn-xtn),90,500) , dtype=\"object\")\n",
    "\n",
    "for i in range(0,xta):\n",
    "\txa_train[i] = xa[i]\n",
    "for i in range(0,xtn):\n",
    "\txn_train[i] = xn[i]\n",
    "for i in range(0,na-xta):\n",
    "\txa_test[i] = xa[xta+i]\n",
    "for i in range(0,nn-xtn):\n",
    "\txn_test[i] = xn[xtn+i]\n",
    "\n",
    "#finding connectivity matrix\n",
    "c_xa = np.ndarray(shape = (xta,90,90) , dtype=\"object\")\n",
    "c_xn = np.ndarray(shape = (xtn,90,90) , dtype=\"object\")\n",
    "\n",
    "#transpose of xa and xn\n",
    "xa_t = np.ndarray(shape = (xta,500,90),dtype=\"object\")\n",
    "xn_t = np.ndarray(shape = (xtn,500,90),dtype=\"object\")\n",
    "\n",
    "#total mean corrected input\n",
    "X_train = np.ndarray(shape = (no_train,),dtype=\"object\")  #(872,90,500)\n",
    "X_test = np.ndarray(shape = (no_test,),dtype=\"object\")  #(872,90,500)\n",
    "Y_train  = np.ndarray(shape = (no_train,) , dtype=\"object\")  #(872,90,500)\n",
    "Y_test  = np.ndarray(shape = (no_test,) , dtype=\"object\")  #(872,90,500)\n",
    "\n",
    "for i in range (0,xta):\n",
    "\tX_train[i] = xa_train[i]\n",
    "for j in range (0,xtn):\n",
    "\tX_train[j + xta] = xn_train[j]\n",
    "\n",
    "\n",
    "for i in range (0,na-xta):\n",
    "\tX_test[i] = xa_test[i]\n",
    "for j in range (0,nn-xtn):\n",
    "\tX_test[(na-xta)+j] = xn_test[j]\n",
    "\n",
    "    \n",
    "xa_train = xa_train.astype(float)\n",
    "xn_train = xn_train.astype(float)\n",
    "xa_t = xa_t.astype(float)\n",
    "xn_t = xn_t.astype(float)\n",
    "for i in range (0, xta):\n",
    "\txa_t[i] = xa_train[i].transpose()\n",
    "\tc_xa[i] = np.matmul(xa_train[i],xa_t[i])\n",
    "\n",
    "for j in range (0, xtn):\n",
    "\txn_t[j] = xn_train[j].transpose()\n",
    "\tc_xn[j] = np.matmul(xn_train[j],xn_t[j])\n",
    "\n",
    "\n",
    "#trace of c_xa and c_xn\n",
    "tr_cxa = np.zeros((xta,1))\n",
    "tr_cxn = np.zeros((xtn,1))\n",
    "\n",
    "\n",
    "for i in range(0, xta):\n",
    "\ttr_cxa[i] = np.trace(c_xa[i])\n",
    "\n",
    "for j in range(0, xtn):\n",
    "\ttr_cxn[j] = np.trace(c_xn[j])\n",
    "\n",
    "for i in range (0,xta):\n",
    "\tc_xa[i] = np.divide(c_xa[i], tr_cxa[i])\n",
    "\n",
    "for j in range (0,xtn):\n",
    "\tc_xn[j] = np.divide(c_xn[j], tr_cxn[j])\n",
    "\n",
    "#finding mean connectivity matrices for asd and neurotypical\n",
    "m_cxa = np.zeros((90,90))\n",
    "m_cxn = np.zeros((90,90))\n",
    "\n",
    "for i in range (0, xta):\n",
    "\tfor j in range (0,90):\n",
    "\t\tfor k in range (0,90):\n",
    "\t\t\tm_cxa[j][k] = m_cxa[j][k] + c_xa[i][j][k]\n",
    "\n",
    "for i in range (0, xtn):\n",
    "\tfor j in range (0,90):\n",
    "\t\tfor k in range (0,90):\n",
    "\t\t\tm_cxn[j][k] = m_cxn[j][k] + c_xn[i][j][k]\n",
    "\n",
    "Co = np.add (m_cxa , m_cxn)\n",
    "Co = np.divide(Co , no_train)\n",
    "\n",
    "m_cxa = np.divide(m_cxa , xta)\n",
    "m_cxn = np.divide(m_cxn , xtn)\n",
    "\n",
    "#Finding the SVD of the connectivity matrix\n",
    "#Bo,xo,Bo_tr = np.linalg.svd(Co, compute_uv=True)\n",
    "#Reshaping the eigen value matrix\n",
    "xo_notsort, Bo_notsort = np.linalg.eig(Co)\n",
    "CSP1 = []\n",
    "xo = sorted(xo_notsort, reverse = True)\n",
    "for i in xo:\n",
    "    CSP1.append(Bo_notsort[xo_notsort==i][0])\n",
    "Bo = np.asarray(CSP1)\n",
    "\n",
    "Xo=np.diag(xo)\n",
    "inverse_Xo = np.linalg.inv(Xo)\n",
    "sqrt_inv = np.sqrt(inverse_Xo)\n",
    "BoT = np.transpose(Bo)\n",
    "\n",
    "#whitening Matrix\n",
    "W = np.matmul(sqrt_inv,BoT)  #(90,90)\n",
    "Wt = np.transpose(W)\n",
    "\n",
    "var_1 = np.matmul(W , m_cxa)\n",
    "m_cxa_bar = np.matmul(var_1 , Wt)   #(90,90)\n",
    "m_cxa_bar_t = np.transpose(m_cxa_bar)\n",
    "\n",
    "#v= np.array_equal(m_cxa_bar, m_cxa_bar_t)\n",
    "#print(v)\n",
    "\n",
    "var_2 = np.matmul(W , m_cxn)\n",
    "m_cxn_bar = np.matmul(var_2 , Wt) #(90,90)\n",
    "m_cxn_bar_t = np.transpose(m_cxn_bar)\n",
    "\n",
    "\n",
    "CSP = []\n",
    "B_notsort , U = linalg.eig(m_cxa_bar, b=m_cxn_bar)\n",
    "B = sorted(B_notsort, reverse = True)\n",
    "for i in B:\n",
    "    CSP.append(U[B_notsort==i][0])\n",
    "CSP_arr = np.asarray(CSP)\n",
    "\n",
    "U_t = np.transpose(CSP_arr)\n",
    "P = np.matmul(U_t,W)\n",
    "P_inv = np.linalg.inv(P)\n",
    "P = P.astype(float)\n",
    "P_inv = P_inv.astype(float)\n",
    "\n",
    "for i in range(0,no_train):\n",
    "\tY_train[i] = np.matmul(P,X_train[i].astype(float))\n",
    "for i in range(0,no_test):\n",
    "\tY_test[i] = np.matmul(P,X_test[i].astype(float))\n",
    "\n",
    "no_feat = 20 # each for mean and max corr\n",
    "tb =int(no_feat/2)\n",
    "nf2 = 2*no_feat\n",
    "\n",
    "f_train_mean = np.ndarray(shape =(no_train,no_feat,1) , dtype = \"object\")\n",
    "f_train_maxcorr = np.ndarray(shape =(no_train,no_feat,1) , dtype = \"object\")\n",
    "f_test_mean = np.ndarray(shape = (no_test,no_feat,1) , dtype=\"object\")\n",
    "f_test_maxcorr = np.ndarray(shape = (no_test,no_feat,1) , dtype=\"object\")\n",
    "f_train = np.ndarray(shape =(no_train,(nf2),1) , dtype = \"object\")\n",
    "f_test = np.ndarray(shape =(no_train,(nf2),1) , dtype = \"object\")\n",
    "\n",
    "for k in range (0,no_train):\n",
    "    for i in range(0,tb):\n",
    "        f_train_mean[k][i] = np.mean(np.trim_zeros(Y_train[k][i]))\n",
    "        f_train_maxcorr[k][i] = np.amax(signal.correlate(np.trim_zeros(Y_train[k][i]),np.trim_zeros(Y_train[k][i])))\n",
    "    cnt5 = tb\n",
    "    for j in range((90-tb),90):\n",
    "        f_train_mean[k][cnt5] = np.mean(np.trim_zeros(Y_train[k][j]))\n",
    "        f_train_maxcorr[k][cnt5] = np.amax(signal.correlate(np.trim_zeros(Y_train[k][j]),np.trim_zeros(Y_train[k][j])))\n",
    "        cnt5 = cnt5+1\n",
    "        \n",
    "for k in range (0,no_test):\n",
    "    for i in range(0,tb):\n",
    "        f_test_mean[k][i] = np.mean(np.trim_zeros(Y_test[k][i]))\n",
    "        f_test_maxcorr[k][i] = np.amax(signal.correlate(np.trim_zeros(Y_test[k][i]),np.trim_zeros(Y_test[k][i])))\n",
    "    cnt6 = tb\n",
    "    for j in range((90-tb),90):\n",
    "        f_test_mean[k][cnt6] = np.mean(np.trim_zeros(Y_test[k][j]))\n",
    "        f_test_maxcorr[k][cnt6] = np.amax(signal.correlate(np.trim_zeros(Y_test[k][j]),np.trim_zeros(Y_test[k][j])))\n",
    "        cnt6 = cnt6+1\n",
    "\n",
    "for k in range (0,no_train):\n",
    "\tfor i in range (0, no_feat):\n",
    "\t\tf_train[k][i] = f_train_mean[k][i]\n",
    "\tfor j in range (no_feat,nf2):\n",
    "\t\tf_train[k][j] = f_train_maxcorr[k][j-no_feat]\n",
    "for k in range (0,no_test):\n",
    "\tfor i in range (0, no_feat):\n",
    "\t\tf_test[k][i] = f_test_mean[k][i]\n",
    "\tfor j in range (no_feat,nf2):\n",
    "\t\tf_test[k][j] = f_test_maxcorr[k][j-no_feat]\n",
    "\n",
    "\n",
    "qw = (2*no_feat)+1\n",
    "\n",
    "fn1_train = np.zeros([no_train,nf2])\n",
    "fn1_test = np.zeros([no_test,nf2])\n",
    "\n",
    "for i in range(0,no_train):\n",
    "\tfor j in range(0,nf2):\n",
    "\t\tfn1_train[i][j] = f_train[i][j][0]\n",
    "for i in range(0,no_test):\n",
    "\tfor j in range(0,nf2):\n",
    "\t\tfn1_test[i][j] = f_test[i][j][0]\n",
    "\n",
    "\n",
    "#Normalizing the data sample wise\n",
    "fn_train = normalize(fn1_train, norm='max', axis=1)\n",
    "fn_test = normalize(fn1_test, norm='max', axis=1)\n",
    "\n",
    "fn_a_train = np.zeros([xta,qw])\n",
    "fn_n_train = np.zeros([xtn,qw])\n",
    "fn_a_test = np.zeros([na-xta,qw])\n",
    "fn_n_test = np.zeros([nn-xtn,qw])\n",
    "\n",
    "#only top tb and bottom tb no. of features(columns) from fn are chosen\n",
    "#the last column of fn_a and fn_n is set to class no: 1 if autistic and 0 if neurotypical\t\n",
    "for i in range(0,xta):\n",
    "    for j in range(0,nf2): \n",
    "    \tfn_a_train[i][j] = fn_train[i][j]\n",
    "    fn_a_train[i][nf2] = 1          #setting class\n",
    "\n",
    "for i in range(0,xtn):\n",
    "    for j in range(0,nf2):\n",
    "        fn_n_train[i][j] = fn_train[i+xta][j] \n",
    "    fn_n_train[i][nf2] = 0        #setting class\n",
    "    \n",
    "for i in range(0,na-xta):\n",
    "    for j in range(0,nf2): \n",
    "    \tfn_a_test[i][j] = fn_test[i][j]\n",
    "    fn_a_test[i][nf2] = 1 \n",
    "\n",
    "for i in range(0,nn-xtn):\n",
    "    for j in range(0,nf2):\n",
    "        fn_n_test[i][j] = fn_test[i+(na-xta)][j]\n",
    "    fn_n_test[i][nf2] = 0        #setting class\n",
    "\n",
    "\n",
    "\n",
    "Xx_train = np.ndarray(shape = (no_train,qw), dtype = object)\n",
    "Xx_test = np.ndarray(shape = (no_test,qw), dtype = object)\n",
    "\n",
    "X_train_s = np.ndarray(shape = (no_train,nf2), dtype = object)\n",
    "X_test_s = np.ndarray(shape = (no_test,nf2), dtype = object)\n",
    "y_test_s = np.zeros([no_test])\n",
    "y_train_s = np.zeros([no_train])\n",
    "\n",
    "for i in range(0,xta):\n",
    "\tXx_train[i] = fn_a_train[i]\n",
    "\n",
    "for j in range(0,xtn):\n",
    "\tXx_train[xta+j] = fn_n_train[j]\n",
    "\n",
    "for i in range(0,na - xta):\n",
    "\tXx_test[i] = fn_a_test[i]\n",
    "\n",
    "for j in range(0,nn - xtn):\n",
    "\tXx_test[(na-xta)+j] = fn_n_test[j]\n",
    "\n",
    "\n",
    "np.random.shuffle(Xx_train)\n",
    "np.random.shuffle(Xx_test)\n",
    "\n",
    "for i in range(0,no_train):\n",
    "\tfor j in range(0,nf2):\n",
    "\t\tX_train_s[i][j] = Xx_train[i][j]\n",
    "\ty_train_s[i] = Xx_train[i][nf2]\n",
    "\n",
    "for i in range(0,no_test):\n",
    "\tfor j in range(0,nf2):\n",
    "\t\tX_test_s[i][j] = Xx_test[i][j]\n",
    "\ty_test_s[i] = Xx_test[i][nf2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('y_pred', (86,))\n",
      "('y_test', (86,))\n",
      "('accuracy = ', 54.651162790697676)\n",
      "('autistic class accuracy = ', 58.13953488372093)\n",
      "('neurotypical class accuracy = ', 51.16279069767442)\n",
      "Confusion matrix \n",
      "\n",
      "[[22 21]\n",
      " [18 25]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.55      0.51      0.53        43\n",
      "        1.0       0.54      0.58      0.56        43\n",
      "\n",
      "avg / total       0.55      0.55      0.55        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_dev = X_train_s.std()\n",
    "gam = 1/(std_dev*nf2)\n",
    "\n",
    "svclassifier = SVC(C=2.0,kernel='rbf',gamma = gam)\n",
    "svclassifier.fit(X_train_s, y_train_s)\n",
    "y_pred_s = svclassifier.predict(X_test_s)\n",
    "print('y_pred',y_pred_s.shape)\n",
    "print('y_test',y_test_s.shape)\n",
    "score=0\n",
    "score_a = 0\n",
    "score_n = 0\n",
    "for i in range(0,no_test):\n",
    "    if(y_pred_s[i]==y_test_s[i]):\n",
    "        score = score+1\n",
    "        if(y_pred_s[i]==1):\n",
    "            score_a = score_a+1\n",
    "        if(y_pred_s[i]==0):\n",
    "           score_n = score_n+1\n",
    "acc = (float(score)*100)/(float(no_test))\n",
    "acc_a = (float(score_a)*100) / (float(na-xta))\n",
    "acc_n = (float(score_n)*100) / (float(nn-xtn))\n",
    "print('accuracy = ',acc)\n",
    "print('autistic class accuracy = ', acc_a)\n",
    "print('neurotypical class accuracy = ',acc_n)\n",
    "print('Confusion matrix \\n')\n",
    "print(confusion_matrix(y_test_s, y_pred_s))\n",
    "print(classification_report(y_test_s,y_pred_s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
