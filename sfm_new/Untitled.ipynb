{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from scipy import linalg,signal\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "asd_data = sio.loadmat('whole_asd_fmri.mat')\n",
    "nt_data = sio.loadmat('whole_tdc_fmri.mat')\n",
    "\n",
    "def normalise_matrix (matrix1, matrix2, matrix3 ):\n",
    "\tfor l in range (0,90):\n",
    "\t\ta11 = np.trim_zeros(matrix2[l])\n",
    "\t\ta11_len = len(a11)\n",
    "\t\tfor m in range (0,a11_len): \n",
    "\t\t\ta11[m] = a11[m] - matrix3[l]\n",
    "\t\tu = 500 - a11_len\n",
    "\t\ta11 = np.pad(a11,(0,u),'constant',constant_values=0)\n",
    "\t\ta11 = np.asarray(a11)\n",
    "\t\tmatrix1[l] = a11\n",
    "\n",
    "\t\n",
    "def mean_row(matrix1):\n",
    "\tr = np.zeros([90,1])\n",
    "\tfor i in range(0,90):\n",
    "\t\tr[i] = np.mean(np.trim_zeros(matrix1[i]))\n",
    "\tr=np.reshape(r,(90,1))\n",
    "\treturn r\n",
    "\n",
    "na = 443\n",
    "nn = 435\n",
    "x = asd_data['x']\n",
    "x = np.transpose(x,(2,1,0))\n",
    "\n",
    "y = nt_data['y']\n",
    "y = np.transpose(y,(2,1,0))\n",
    "\n",
    "\n",
    "# autistic and neurotypical arrays\n",
    "a = np.ndarray(shape = (438,) , dtype=\"object\")\n",
    "n = np.ndarray(shape = (434,) , dtype=\"object\")\n",
    "\n",
    "#mean of each row of the matrices use axis=1\n",
    "ma = np.ndarray(shape = (438,90,1) , dtype=\"object\")\n",
    "mn = np.ndarray(shape = (434,90,1) , dtype=\"object\")\n",
    "\n",
    "#normalised input matrices\n",
    "xa = np.ndarray(shape = (438,) , dtype=\"object\")\n",
    "xn = np.ndarray(shape = (434,) , dtype=\"object\")\n",
    "\n",
    "cnt1=0\n",
    "for i in range(0,na): \n",
    "\tif((i != 6) and (i != 7) and (i != 10) and (i!= 325) and (i!= 330) ):\n",
    "\t\ta[cnt1] = x[i]\n",
    "\t\tcnt1 = cnt1+1\n",
    "\t\t\n",
    "\n",
    "cnt2=0\n",
    "for j in range(0,nn):\n",
    "\tif(( j != 62)):\n",
    "\t\tn[cnt2] = y[j]\n",
    "\t\tcnt2 = cnt2+1\n",
    "\n",
    "na=438\n",
    "nn=434\n",
    "for i in range(0, na):\n",
    "\txa[i] = np.zeros((90,500))\n",
    "\n",
    "for j in range(0, nn):\n",
    "\txn[j] = np.zeros((90,500))\n",
    "\n",
    "#finding mean of every row in 2d matrix for each subject\n",
    "\n",
    "for i in range(0,na):\n",
    "\tma[i] = mean_row(a[i])\n",
    "\n",
    "for j in range(0,nn):\n",
    "\tmn[j] = mean_row(n[j])\n",
    "\n",
    "#getting normalised matrix\n",
    "\n",
    "for i in range(0,na):\n",
    "\tnormalise_matrix(xa[i],a[i],ma[i])\n",
    "\t\n",
    "for j in range(0,nn):\n",
    "\tnormalise_matrix(xn[j],n[j],mn[j])\n",
    "\n",
    "no_train = 786\n",
    "no_test = (na+nn) - no_train\n",
    "xta = int(no_train/2) + 2       #329\n",
    "xtn = no_train - xta            #326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred (86,)\n",
      "y_test (86,)\n",
      "accuracy =  68.6046511627907\n",
      "autistic class accuracy =  72.09302325581395\n",
      "neurotypical class accuracy =  65.11627906976744\n",
      "Confusion matrix \n",
      "\n",
      "[[28 15]\n",
      " [12 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.65      0.67        43\n",
      "         1.0       0.67      0.72      0.70        43\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        86\n",
      "   macro avg       0.69      0.69      0.69        86\n",
      "weighted avg       0.69      0.69      0.69        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#np.random.shuffle(xa)   #shuffles the matrix and saves in itself, returns nothing\n",
    "#np.random.shuffle(xn)\n",
    "\n",
    "xa_train = np.ndarray(shape = (xta,90,500) , dtype=\"object\")\n",
    "xa_test = np.ndarray(shape = ((na-xta),90,500) , dtype=\"object\")\n",
    "xn_train = np.ndarray(shape = (xtn,90,500) , dtype=\"object\")\n",
    "xn_test = np.ndarray(shape = ((nn-xtn),90,500) , dtype=\"object\")\n",
    "\n",
    "for i in range(0,xta):\n",
    "\txa_train[i] = xa[i]\n",
    "for i in range(0,xtn):\n",
    "\txn_train[i] = xn[i]\n",
    "for i in range(0,na-xta):\n",
    "\txa_test[i] = xa[xta+i]\n",
    "for i in range(0,nn-xtn):\n",
    "\txn_test[i] = xn[xtn+i]\n",
    "\n",
    "#finding connectivity matrix\n",
    "c_xa = np.ndarray(shape = (xta,90,90) , dtype=\"object\")\n",
    "c_xn = np.ndarray(shape = (xtn,90,90) , dtype=\"object\")\n",
    "\n",
    "#transpose of xa and xn\n",
    "xa_t = np.ndarray(shape = (xta,500,90),dtype=\"object\")\n",
    "xn_t = np.ndarray(shape = (xtn,500,90),dtype=\"object\")\n",
    "\n",
    "#total mean corrected input\n",
    "X_train = np.ndarray(shape = (no_train,),dtype=\"object\")  #(872,90,500)\n",
    "X_test = np.ndarray(shape = (no_test,),dtype=\"object\")  #(872,90,500)\n",
    "Y_train  = np.ndarray(shape = (no_train,) , dtype=\"object\")  #(872,90,500)\n",
    "Y_test  = np.ndarray(shape = (no_test,) , dtype=\"object\")  #(872,90,500)\n",
    "\n",
    "for i in range (0,xta):\n",
    "\tX_train[i] = xa_train[i]\n",
    "for j in range (0,xtn):\n",
    "\tX_train[j + xta] = xn_train[j]\n",
    "\n",
    "\n",
    "for i in range (0,na-xta):\n",
    "\tX_test[i] = xa_test[i]\n",
    "for j in range (0,nn-xtn):\n",
    "\tX_test[(na-xta)+j] = xn_test[j]\n",
    "\n",
    "    \n",
    "xa_train = xa_train.astype(float)\n",
    "xn_train = xn_train.astype(float)\n",
    "xa_t = xa_t.astype(float)\n",
    "xn_t = xn_t.astype(float)\n",
    "for i in range (0, xta):\n",
    "\txa_t[i] = xa_train[i].transpose()\n",
    "\tc_xa[i] = np.matmul(xa_train[i],xa_t[i])\n",
    "\n",
    "for j in range (0, xtn):\n",
    "\txn_t[j] = xn_train[j].transpose()\n",
    "\tc_xn[j] = np.matmul(xn_train[j],xn_t[j])\n",
    "\n",
    "\n",
    "#trace of c_xa and c_xn\n",
    "tr_cxa = np.zeros((xta,1))\n",
    "tr_cxn = np.zeros((xtn,1))\n",
    "\n",
    "\n",
    "for i in range(0, xta):\n",
    "\ttr_cxa[i] = np.trace(c_xa[i])\n",
    "\n",
    "for j in range(0, xtn):\n",
    "\ttr_cxn[j] = np.trace(c_xn[j])\n",
    "\n",
    "for i in range (0,xta):\n",
    "\tc_xa[i] = np.divide(c_xa[i], tr_cxa[i])\n",
    "\n",
    "for j in range (0,xtn):\n",
    "\tc_xn[j] = np.divide(c_xn[j], tr_cxn[j])\n",
    "\n",
    "#finding mean connectivity matrices for asd and neurotypical\n",
    "m_cxa = np.zeros((90,90))\n",
    "m_cxn = np.zeros((90,90))\n",
    "\n",
    "for i in range (0, xta):\n",
    "\tfor j in range (0,90):\n",
    "\t\tfor k in range (0,90):\n",
    "\t\t\tm_cxa[j][k] = m_cxa[j][k] + c_xa[i][j][k]\n",
    "\n",
    "for i in range (0, xtn):\n",
    "\tfor j in range (0,90):\n",
    "\t\tfor k in range (0,90):\n",
    "\t\t\tm_cxn[j][k] = m_cxn[j][k] + c_xn[i][j][k]\n",
    "\n",
    "#Co = np.add (m_cxa , m_cxn)\n",
    "#Co = np.divide(Co , no_train)\n",
    "\n",
    "\n",
    "m_cxa = np.divide(m_cxa , xta)\n",
    "m_cxn = np.divide(m_cxn , xtn)\n",
    "Co = m_cxa + m_cxn\n",
    "\n",
    "#Finding the SVD of the connectivity matrix\n",
    "#Bo,xo,Bo_tr = np.linalg.svd(Co, compute_uv=True)\n",
    "#Reshaping the eigen value matrix\n",
    "\n",
    "xo_notsort, Bo_notsort = np.linalg.eig(Co)\n",
    "CSP1 = []\n",
    "xo = sorted(xo_notsort, reverse = True)\n",
    "for i in xo:\n",
    "    CSP1.append(Bo_notsort[xo_notsort==i][0])\n",
    "Bo = np.asarray(CSP1)\n",
    "Xo=np.diagflat(xo)\n",
    "\n",
    "inverse_Xo = np.linalg.inv(Xo)\n",
    "sqrt_inv = np.sqrt(inverse_Xo)\n",
    "BoT = np.transpose(Bo)\n",
    "\n",
    "#sio.savemat('Bo_eig_sort.mat',mdict ={'Bo' : Bo})\n",
    "#sio.savemat('Xo_eig_sort.mat',mdict ={'Xo' : Xo})\n",
    "\n",
    "#whitening Matrix\n",
    "W = np.matmul(sqrt_inv,BoT)  #(90,90)\n",
    "Wt = np.transpose(W)\n",
    "\n",
    "#sio.savemat('wt.mat', mdict ={'W' : W})\n",
    "\n",
    "var_1 = np.matmul(W , m_cxa)\n",
    "m_cxa_bar = np.matmul(var_1 , Wt)   #(90,90)\n",
    "m_cxa_bar_t = np.transpose(m_cxa_bar)\n",
    "\n",
    "#v= np.array_equal(m_cxa_bar, m_cxa_bar_t)\n",
    "#print(v)\n",
    "\n",
    "var_2 = np.matmul(W , m_cxn)\n",
    "m_cxn_bar = np.matmul(var_2 , Wt) #(90,90)\n",
    "m_cxn_bar_t = np.transpose(m_cxn_bar)\n",
    "\n",
    "\n",
    "CSP = []\n",
    "B_notsort , U = linalg.eig(m_cxa_bar, b=m_cxn_bar)\n",
    "B = sorted(B_notsort, reverse = False)\n",
    "for i in B:\n",
    "    CSP.append(U[B_notsort==i][0])\n",
    "CSP_arr = np.asarray(CSP)\n",
    "\n",
    "\n",
    "#sio.savemat('U_svd.mat',mdict={'U' t: CSP_arr})\n",
    "#sio.savemat('B_svd.mat',mdict={'B' : B})\n",
    "\n",
    "U_t = np.transpose(CSP_arr)\n",
    "P = np.matmul(U_t,W)\n",
    "P_inv = np.linalg.inv(P)\n",
    "P = P.astype(float)\n",
    "P_inv = P_inv.astype(float)\n",
    "\n",
    "for i in range(0,no_train):\n",
    "    Y_train[i] = np.matmul(P,X_train[i].astype(float))\n",
    "for i in range(0,no_test):\n",
    "    Y_test[i] = np.matmul(P,X_test[i].astype(float))\n",
    "\n",
    "no_feat = 90 # each for mean and max corr\n",
    "tb =int(no_feat/2)\n",
    "\n",
    "\n",
    "f_train = np.ndarray(shape =(no_train,(no_feat),1) , dtype = \"object\")\n",
    "f_test = np.ndarray(shape =(no_train,(no_feat),1) , dtype = \"object\")\n",
    "\n",
    "for k in range (0,no_train):\n",
    "    for i in range(0,tb):  \n",
    "        #f_train[k][i] = np.mean(np.trim_zeros(Y_train[k][i]))\n",
    "        f_train[k][i] = np.log10(np.var(np.trim_zeros(Y_train[k][i])))\n",
    "        #f_train[k][i] = np.amax(signal.correlate(np.trim_zeros(Y_train[k][i]),np.trim_zeros(Y_train[k][i])))\n",
    "    cnt5 = tb\n",
    "    for j in range((90-tb),90):\n",
    "        #f_train[k][cnt5] = np.mean(np.trim_zeros(Y_train[k][j]))  \n",
    "        f_train[k][cnt5] = np.log10(np.var(np.trim_zeros(Y_train[k][j])))\n",
    "        #f_train[k][cnt5] = np.amax(signal.correlate(np.trim_zeros(Y_train[k][j]),np.trim_zeros(Y_train[k][j])))\n",
    "        cnt5 = cnt5+1\n",
    "\n",
    "for k in range (0,no_test):\n",
    "    for i in range(0,tb):\n",
    "        #f_test[k][i] = np.mean(np.trim_zeros(Y_test[k][i]))  \n",
    "        f_test[k][i] = np.log10(np.var(np.trim_zeros(Y_test[k][i])))\n",
    "        #f_test[k][i] = np.amax(signal.correlate(np.trim_zeros(Y_test[k][i]),np.trim_zeros(Y_test[k][i])))\n",
    "    cnt6 = tb\n",
    "    for j in range((90-tb),90):\n",
    "        #f_test[k][cnt6] = np.mean(np.trim_zeros(Y_test[k][j]))\n",
    "        f_test[k][cnt6] = np.log10(np.var(np.trim_zeros(Y_test[k][j])))\n",
    "        #f_test[k][cnt6] = np.amax(signal.correlate(np.trim_zeros(Y_test[k][j]),np.trim_zeros(Y_test[k][j])))\n",
    "        cnt6 = cnt6+1\n",
    "\n",
    "qw = (no_feat)+1\n",
    "\n",
    "fn1_train = np.zeros([no_train,no_feat])\n",
    "fn1_test = np.zeros([no_test,no_feat])\n",
    "\n",
    "for i in range(0,no_train):\n",
    "    for j in range(0,no_feat):\n",
    "        fn1_train[i][j] = f_train[i][j][0]\n",
    "for i in range(0,no_test):\n",
    "    for j in range(0,no_feat):\n",
    "        fn1_test[i][j] = f_test[i][j][0]\n",
    "\n",
    "\n",
    "#Normalizing the data sample wise\n",
    "fn_train = normalize(fn1_train, norm='max', axis=1)\n",
    "fn_test = normalize(fn1_test, norm='max', axis=1)\n",
    "\n",
    "fn_a_train = np.zeros([xta,qw])\n",
    "fn_n_train = np.zeros([xtn,qw])\n",
    "fn_a_test = np.zeros([na-xta,qw])\n",
    "fn_n_test = np.zeros([nn-xtn,qw])\n",
    "\n",
    "#only top tb and bottom tb no. of features(columns) from fn are chosen\n",
    "#the last column of fn_a and fn_n is set to class no: 1 if autistic and 0 if neurotypical\t\n",
    "for i in range(0,xta):\n",
    "    for j in range(0,no_feat): \n",
    "        fn_a_train[i][j] = fn_train[i][j]\n",
    "    fn_a_train[i][no_feat] = 1          #setting class\n",
    "\n",
    "for i in range(0,xtn):\n",
    "    for j in range(0,no_feat):\n",
    "        fn_n_train[i][j] = fn_train[i+xta][j] \n",
    "    fn_n_train[i][no_feat] = 0        #setting class\n",
    "\n",
    "for i in range(0,na-xta):\n",
    "    for j in range(0,no_feat): \n",
    "        fn_a_test[i][j] = fn_test[i][j]\n",
    "    fn_a_test[i][no_feat] = 1 \n",
    "\n",
    "for i in range(0,nn-xtn):\n",
    "    for j in range(0,no_feat):\n",
    "        fn_n_test[i][j] = fn_test[i+(na-xta)][j]\n",
    "    fn_n_test[i][no_feat] = 0        #setting class\n",
    "\n",
    "\n",
    "Xx_train = np.ndarray(shape = (no_train,qw), dtype = object)\n",
    "Xx_test = np.ndarray(shape = (no_test,qw), dtype = object)\n",
    "\n",
    "X_train_s = np.ndarray(shape = (no_train,no_feat), dtype = object)\n",
    "X_test_s = np.ndarray(shape = (no_test,no_feat), dtype = object)\n",
    "y_test_s = np.zeros([no_test])\n",
    "y_train_s = np.zeros([no_train])\n",
    "\n",
    "for i in range(0,xta):\n",
    "    Xx_train[i] = fn_a_train[i]\n",
    "\n",
    "for j in range(0,xtn):\n",
    "    Xx_train[xta+j] = fn_n_train[j]\n",
    "\n",
    "for i in range(0,na - xta):\n",
    "    Xx_test[i] = fn_a_test[i]\n",
    "\n",
    "for j in range(0,nn - xtn):\n",
    "    Xx_test[(na-xta)+j] = fn_n_test[j]\n",
    "\n",
    "\n",
    "#np.random.shuffle(Xx_train)\n",
    "#np.random.shuffle(Xx_test)\n",
    "\n",
    "for i in range(0,no_train):\n",
    "    for j in range(0,no_feat):\n",
    "        X_train_s[i][j] = Xx_train[i][j]\n",
    "    y_train_s[i] = Xx_train[i][no_feat]\n",
    "\n",
    "for i in range(0,no_test):\n",
    "    for j in range(0,no_feat):\n",
    "        X_test_s[i][j] = Xx_test[i][j]\n",
    "    y_test_s[i] = Xx_test[i][no_feat]\n",
    "\n",
    "std_dev = X_train_s.std()\n",
    "gam = 1/(std_dev*no_feat)\n",
    "\n",
    "svclassifier = SVC(C=10.0,kernel='rbf',gamma = gam)\n",
    "svclassifier.fit(X_train_s, y_train_s)\n",
    "y_pred_s = svclassifier.predict(X_test_s)\n",
    "print('y_pred',y_pred_s.shape)\n",
    "print('y_test',y_test_s.shape)\n",
    "score=0\n",
    "score_a = 0\n",
    "score_n = 0\n",
    "for i in range(0,no_test):\n",
    "    if(y_pred_s[i]==y_test_s[i]):\n",
    "        score = score+1\n",
    "        if(y_pred_s[i]==1):\n",
    "            score_a = score_a+1\n",
    "        if(y_pred_s[i]==0):\n",
    "           score_n = score_n+1\n",
    "acc = (float(score)*100)/(float(no_test))\n",
    "acc_a = (float(score_a)*100) / (float(na-xta))\n",
    "acc_n = (float(score_n)*100) / (float(nn-xtn))\n",
    "print('accuracy = ',acc)\n",
    "print('autistic class accuracy = ', acc_a)\n",
    "print('neurotypical class accuracy = ',acc_n)\n",
    "print('Confusion matrix \\n')\n",
    "print(confusion_matrix(y_test_s, y_pred_s))\n",
    "print(classification_report(y_test_s,y_pred_s))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
